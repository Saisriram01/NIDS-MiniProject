{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42354/2995610886.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df1)\n",
      "/tmp/ipykernel_42354/2995610886.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df2)\n"
     ]
    }
   ],
   "source": [
    "#Read final dataset for work\n",
    "path=\"/home/dmacs/Downloads/Mini_Project/Beth_dataset/labelled_training_data.csv\"  # Path is the dataset path. copy path from the drive and paste here\n",
    "df=pd.read_csv(path,low_memory=False)\n",
    "\n",
    "df1 = pd.read_csv(\"/home/dmacs/Downloads/Mini_Project/Beth_dataset/labelled_testing_data.csv\")\n",
    "df2 = pd.read_csv(\"/home/dmacs/Downloads/Mini_Project/Beth_dataset/labelled_validation_data.csv\")\n",
    "\n",
    "df = df.append(df1)\n",
    "df = df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'processId', 'threadId', 'parentProcessId', 'userId',\n",
       "       'mountNamespace', 'processName', 'hostName', 'eventId', 'eventName',\n",
       "       'stackAddresses', 'argsNum', 'returnValue', 'args', 'sus', 'evil'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evil Records:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evil = df[df['evil']==1]\n",
    "normal = df[df['evil']==0]\n",
    "print(\"Evil Records:\\n\")\n",
    "# pd.DataFrame(evil)['mountNamespace'].nunique()\n",
    "pd.DataFrame(normal)['mountNamespace'].nunique()\n",
    "\n",
    "# print(\"\\n\\nNormal Records:\\n\")\n",
    "# pd.DataFrame(normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_evil = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df[[\"hostName\",\"processId\", \"parentProcessId\", \"userId\", \"mountNamespace\", \"eventId\", \"argsNum\", \"returnValue\",\"sus\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hostName</th>\n",
       "      <th>processId</th>\n",
       "      <th>parentProcessId</th>\n",
       "      <th>userId</th>\n",
       "      <th>mountNamespace</th>\n",
       "      <th>eventId</th>\n",
       "      <th>argsNum</th>\n",
       "      <th>returnValue</th>\n",
       "      <th>sus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ip-10-100-1-120</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4026532231</td>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ip-10-100-1-120</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4026532231</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ip-10-100-1-120</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>4026532231</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ip-10-100-1-120</td>\n",
       "      <td>7347</td>\n",
       "      <td>7341</td>\n",
       "      <td>0</td>\n",
       "      <td>4026531840</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ip-10-100-1-120</td>\n",
       "      <td>7347</td>\n",
       "      <td>7341</td>\n",
       "      <td>0</td>\n",
       "      <td>4026531840</td>\n",
       "      <td>1005</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hostName  processId  parentProcessId  userId  mountNamespace  \\\n",
       "0  ip-10-100-1-120        381                1     100      4026532231   \n",
       "1  ip-10-100-1-120        381                1     100      4026532231   \n",
       "2  ip-10-100-1-120        381                1     100      4026532231   \n",
       "3  ip-10-100-1-120       7347             7341       0      4026531840   \n",
       "4  ip-10-100-1-120       7347             7341       0      4026531840   \n",
       "\n",
       "   eventId  argsNum  returnValue  sus  \n",
       "0      157        5            0    1  \n",
       "1        3        1            0    1  \n",
       "2     1010        0            0    1  \n",
       "3       21        2           -2    1  \n",
       "4     1005        4            0    1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target column encoding\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_text_index(df,name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ip-10-100-1-120': 0, 'ip-10-100-1-129': 1, 'ip-10-100-1-165': 2, 'ip-10-100-1-169': 3, 'ip-10-100-1-173': 4, 'ip-10-100-1-217': 5, 'ip-10-100-1-28': 6, 'ip-10-100-1-34': 7, 'ip-10-100-1-55': 8, 'ip-10-100-1-57': 9, 'ip-10-100-1-79': 10, 'ubuntu': 11}\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit_transform(df['hostName'])\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(unprocessed_data):\n",
    "    data = unprocessed_data.copy()\n",
    "    data[\"processId\"] = data[\"processId\"].map(lambda x: 0 if x in [0, 1, 2] else 1)  # Map to OS/not OS\n",
    "    data[\"parentProcessId\"] = data[\"parentProcessId\"].map(lambda x: 0 if x in [0, 1, 2] else 1)  # Map to OS/not OS\n",
    "    data[\"userId\"] = data[\"userId\"].map(lambda x: 0 if x < 1000 else 1)  # Map to OS/not OS\n",
    "    data[\"mountNamespace\"] = data[\"mountNamespace\"].map(lambda x: 0 if x == 4026531840 else 1)  # Map to mount access to mnt/ (all non-OS users) /elsewhere\n",
    "    data[\"eventId\"] = data[\"eventId\"]  # Keep eventId values (requires knowing max value)\n",
    "    data[\"returnValue\"] = data[\"returnValue\"].map(lambda x: 0 if x == 0 else (1 if x > 0 else 2))  # Map to success/success with value/error\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the numeric column\n",
    "def  encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "  if mean is None:\n",
    "    mean= df[name].mean()\n",
    "\n",
    "  if sd is None:\n",
    "    sd=df[name].std()\n",
    "\n",
    "  df[name] = (df[name] - mean) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode_numeric_zscore(df,'mountNamespace')\n",
    "# encode_numeric_zscore(df,'threadId')\n",
    "# encode_numeric_zscore(df,'processId')\n",
    "# encode_numeric_zscore(df,'timestamp')\n",
    "# encode_numeric_zscore(df,'parentProcessId')\n",
    "# encode_numeric_zscore(df,'eventId')\n",
    "# encode_numeric_zscore(df,'returnValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hostName</th>\n",
       "      <th>processId</th>\n",
       "      <th>parentProcessId</th>\n",
       "      <th>userId</th>\n",
       "      <th>mountNamespace</th>\n",
       "      <th>eventId</th>\n",
       "      <th>argsNum</th>\n",
       "      <th>returnValue</th>\n",
       "      <th>sus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1005</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hostName  processId  parentProcessId  userId  mountNamespace  eventId  \\\n",
       "0         0          1                0       0               1      157   \n",
       "1         0          1                0       0               1        3   \n",
       "2         0          1                0       0               1     1010   \n",
       "3         0          1                1       0               0       21   \n",
       "4         0          1                1       0               0     1005   \n",
       "\n",
       "   argsNum  returnValue  sus  \n",
       "0        5            0    1  \n",
       "1        1            0    1  \n",
       "2        0            0    1  \n",
       "3        2            2    1  \n",
       "4        4            0    1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hostNmae = encode_text_index(df,'hostName')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy - Classification\n",
    "# x_columns = df.columns.drop('evil')\n",
    "x_columns = df.columns\n",
    "x = df[x_columns].values\n",
    "\n",
    "dummies = pd.get_dummies(df_with_evil['evil']) # Classification\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, shuffle = True, random_state=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 128)\n",
    "        self.fc4 = nn.Linear(128, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, patience=5):\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Validate\n",
    "        val_loss, _ = evaluate_model(model, criterion, val_loader)\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"Early stopping triggered. No improvement in validation loss for {} epochs.\".format(patience))\n",
    "            break\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Validation Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return epoch_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the model architecture\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 128)\n",
    "        self.fc4 = nn.Linear(128, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, patience=5):\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Validate\n",
    "        val_loss, _ = evaluate_model(model, criterion, val_loader)\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"Early stopping triggered. No improvement in validation loss for {} epochs.\".format(patience))\n",
    "            break\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Validation Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "# Load the dataset\n",
    "# Split the dataset into train, validation, and test sets\n",
    "x_train, x_val_test, y_train, y_val_test = train_test_split(x, y, test_size=0.2)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=0.5)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.argmax(axis=1), dtype=torch.int64)  # Assuming y_train is one-hot encoded\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.argmax(axis=1), dtype=torch.int64)  # Assuming y_val is one-hot encoded\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.argmax(axis=1), dtype=torch.int64)  # Assuming y_test is one-hot encoded\n",
    "\n",
    "# Create DataLoader for train, validation, and test sets\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "# Define the model\n",
    "model = MyModel(input_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)  # Corrected learning rate parameter name\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "best_model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, patience=5)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "evaluate_model(model, criterion, test_loader)\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model, 'best_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "x_train, x_val_test, y_train, y_val_test = train_test_split(x, y, test_size=0.2)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=0.5)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.argmax(axis=1), dtype=torch.int64)  # Assuming y_train is one-hot encoded\n",
    "x_val_tensor = torch.tensor(x_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.argmax(axis=1), dtype=torch.int64)  # Assuming y_val is one-hot encoded\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.argmax(axis=1), dtype=torch.int64)  # Assuming y_test is one-hot encoded\n",
    "\n",
    "# Create DataLoader for train, validation, and test sets\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "# Define the model\n",
    "model = MyModel(input_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "best_model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, patience=5)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "evaluate_model(best_model, criterion, test_loader)\n",
    "\n",
    "# Save the best model\n",
    "torch.save(best_model.state_dict(),  'best_model.pth')\n",
    "# save_model(best_model, 'best_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
